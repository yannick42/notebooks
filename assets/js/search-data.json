{
  
    
        "post0": {
            "title": "Superstore Sales Dataset",
            "content": ". Superstore Sales Dataset : https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting . TODO : . [ ] find correlations... | [ ] Try to use an application of PCA (?) | . !pip install kaggle --upgrade . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) . import os from getpass import getpass kaggle_username = input(&quot;Kaggle USERNAME : &quot;) os.environ[&#39;KAGGLE_USERNAME&#39;] = kaggle_username kaggle_key = getpass(&quot;Kaggle KEY for &quot;+os.environ.get(&#39;KAGGLE_USERNAME&#39;)+&quot;: &quot;) os.environ[&quot;KAGGLE_KEY&quot;] = kaggle_key . Kaggle USERNAME : yannick42 Kaggle KEY for yannick42: ·········· . !kaggle datasets download -d rohitsahoo/sales-forecasting !unzip -n sales-forecasting.zip !ls -la . Downloading sales-forecasting.zip to /content 0% 0.00/480k [00:00&lt;?, ?B/s] 100% 480k/480k [00:00&lt;00:00, 106MB/s] Archive: sales-forecasting.zip inflating: train.csv total 2580 drwxr-xr-x 1 root root 4096 Apr 21 15:47 . drwxr-xr-x 1 root root 4096 Apr 21 15:44 .. drwxr-xr-x 1 root root 4096 Apr 8 13:31 .config -rw-r--r-- 1 root root 491942 Apr 21 15:47 sales-forecasting.zip drwxr-xr-x 1 root root 4096 Apr 8 13:32 sample_data -rw-r--r-- 1 root root 2129689 Sep 11 2020 train.csv . import pandas as pd import numpy as np np.random.seed(42) from matplotlib import pyplot as plt import seaborn as sns %matplotlib inline # =&gt; ??? &quot;&quot;&quot; 18 columns : - 1 numeric - sales (in $) - 16 strings - order date - ship date - category - sub-category - ... &quot;&quot;&quot; df = pd.read_csv(&#39;train.csv&#39;, parse_dates=True, infer_datetime_format=True) . &quot;&quot;&quot; - Postal Code could be filled by using the city name and using what other lines with the same city name uses ... ? (but only 11 rows have this problem on 9800 sales) &quot;&quot;&quot; df[&#39;Sales&#39;].describe() . count 9800.000000 mean 230.769059 std 626.651875 min 0.444000 25% 17.248000 50% 54.490000 75% 210.605000 max 22638.480000 Name: Sales, dtype: float64 . df.head() # first 5 rows . Row ID Order ID Order Date Ship Date Ship Mode Customer ID Customer Name Segment Country City State Postal Code Region Product ID Category Sub-Category Product Name Sales . 0 1 | CA-2017-152156 | 08/11/2017 | 11/11/2017 | Second Class | CG-12520 | Claire Gute | Consumer | United States | Henderson | Kentucky | 42420.0 | South | FUR-BO-10001798 | Furniture | Bookcases | Bush Somerset Collection Bookcase | 261.9600 | . 1 2 | CA-2017-152156 | 08/11/2017 | 11/11/2017 | Second Class | CG-12520 | Claire Gute | Consumer | United States | Henderson | Kentucky | 42420.0 | South | FUR-CH-10000454 | Furniture | Chairs | Hon Deluxe Fabric Upholstered Stacking Chairs,... | 731.9400 | . 2 3 | CA-2017-138688 | 12/06/2017 | 16/06/2017 | Second Class | DV-13045 | Darrin Van Huff | Corporate | United States | Los Angeles | California | 90036.0 | West | OFF-LA-10000240 | Office Supplies | Labels | Self-Adhesive Address Labels for Typewriters b... | 14.6200 | . 3 4 | US-2016-108966 | 11/10/2016 | 18/10/2016 | Standard Class | SO-20335 | Sean O&#39;Donnell | Consumer | United States | Fort Lauderdale | Florida | 33311.0 | South | FUR-TA-10000577 | Furniture | Tables | Bretford CR4500 Series Slim Rectangular Table | 957.5775 | . 4 5 | US-2016-108966 | 11/10/2016 | 18/10/2016 | Standard Class | SO-20335 | Sean O&#39;Donnell | Consumer | United States | Fort Lauderdale | Florida | 33311.0 | South | OFF-ST-10000760 | Office Supplies | Storage | Eldon Fold &#39;N Roll Cart System | 22.3680 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; plt.figure(figsize=(25,5)) ax = sns.boxplot( y=&#39;Segment&#39;, x=&#39;Sales&#39;, orient=&quot;h&quot;, # horizontal data=df.query(&#39;Segment == &quot;Consumer&quot; | Segment == &quot;Corporate&quot; | Segment == &quot;Home Office&quot;&#39;), showmeans=True, showfliers=True, # (default=True) False to remove outliers flierprops=dict( marker=&#39;x&#39;, markerfacecolor=None, markersize=6, markeredgecolor=&#39;red&#39; ) ) ax.set(xlabel=&#39;Sales in $&#39;, xlim=(0, None)) plt.show() . df[&#39;month&#39;] = pd.to_datetime(df[&#39;Order Date&#39;]).dt.month df[&#39;year&#39;] = pd.to_datetime(df[&#39;Order Date&#39;]).dt.to_period(&#39;Y&#39;) #print(df.month.head()) #print(df.year.head()) df_grouped = df.groupby([&#39;month&#39;, &#39;year&#39;]).size().to_frame(&#39;size&#39;) # to name the size column... &#39;cause size() returns a Series object total_sales = df_grouped[&#39;size&#39;].sum() #print(df_grouped) piv = pd.pivot_table(df_grouped, values=&quot;size&quot;,index=[&quot;year&quot;], columns=[&quot;month&quot;], fill_value=0) sns.heatmap(piv, xticklabels=[&#39;Jan&#39;, &#39;Feb&#39;, &#39;Mar&#39;, &#39;Apr&#39;, &#39;May&#39;, &#39;Jun&#39;, &#39;Jul&#39;, &#39;Aug&#39;, &#39;Sep&#39;, &#39;Oct&#39;, &#39;Nov&#39;, &#39;Dec&#39;], annot=True, fmt=&quot;d&quot;, linewidths=0.5, cmap=&quot;Blues&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0fae44a690&gt; . plt.figure(figsize=(14,6)) # generated in the cell above df_grouped_dollar = df.groupby([&#39;month&#39;, &#39;year&#39;]).sum(&#39;Sales&#39;) piv_dollar = pd.pivot_table(df_grouped_dollar, values=&quot;Sales&quot;,index=[&quot;year&quot;], columns=[&quot;month&quot;], fill_value=0) ax = sns.heatmap(piv_dollar, xticklabels=[&#39;Jan&#39;, &#39;Feb&#39;, &#39;Mar&#39;, &#39;Apr&#39;, &#39;May&#39;, &#39;Jun&#39;, &#39;Jul&#39;, &#39;Aug&#39;, &#39;Sep&#39;, &#39;Oct&#39;, &#39;Nov&#39;, &#39;Dec&#39;], annot=True, fmt=&quot;g&quot;, linewidths=1.5, cmap=&quot;Greens&quot;) ax.set_title(&#39;Sales in $&#39;) total_sales_in_dollar = df_grouped_dollar[&#39;Sales&#39;].sum() print(&quot;Total value over 4 years : &quot;+str(round(total_sales_in_dollar / 1000 / 1000, 3))+&quot; M$&quot;) print(&quot;Mean sale value : &quot;+str(round(total_sales_in_dollar/total_sales))+&quot;$&quot;) plt.show() . Total value over 4 years : 2.262 M$ Mean sale value : 231$ . !pip install --upgrade pyshp !pip install cartopy==0.19.0.post1 #!pip install cartopy #!pip install git+https://github.com/SciTools/cartopy.git . !pip uninstall -y shapely # to prevent this error : https://stackoverflow.com/questions/60111684/geometry-must-be-a-point-or-linestring-error-using-cartopy !pip install shapely --no-binary shapely . import requests for file in [&#39;st99_d00.shp&#39;, &#39;st99_d00.shx&#39;, &#39;st99_d00.dbf&#39;]: url = &#39;https://github.com/MichiganNLP/geoclustering/raw/master/&#39; + file r = requests.get(url, allow_redirects=True) open(file, &#39;wb&#39;).write(r.content) . import matplotlib.patches as mpatches import matplotlib.pyplot as plt import matplotlib as mpl #from mpl_toolkits.basemap import Basemap as Basemap # Deprecated in favor of Cartopy (since 2016) import shapely.geometry as sgeom import cartopy.crs as ccrs import cartopy.io.shapereader as shpreader # to hide Shapely 2.0 (future) warnings import warnings from shapely.errors import ShapelyDeprecationWarning warnings.filterwarnings(&quot;ignore&quot;, category=ShapelyDeprecationWarning) # Number of Sales per state #df_2 = df.groupby([&#39;State&#39;]).size() # Number of Sales in $ per state df_2 = df.groupby([&#39;State&#39;]).sum(&#39;Sales&#39;)[&#39;Sales&#39;] &quot;&quot;&quot; #plt.figure(figsize=(18,9)) m = Basemap( llcrnrlon=-121, llcrnrlat=20, urcrnrlon=-62, urcrnrlat=51, projection=&#39;lcc&#39;, lat_1=32, lat_2=45, lon_0=-95 ) m.readshapefile(&#39;st99_d00&#39;, name=&#39;states&#39;, drawbounds=True) m.drawcountries(color=&#39;#ffffff&#39;, linewidth=0.5) m.fillcontinents(color=&#39;#c0c0c0&#39;, lake_color=&#39;#ffffff&#39;) # draw points on the map #lats = [24.48237852, 26.89169118] #lons = [118.1558955, 117.1760012] #x, y = m(lons, lats) #plt.plot(x, y, &#39;bo&#39;, color=&#39;r&#39;, markersize=5) &quot;&quot;&quot; fig = plt.figure(figsize=(12,8)) min_worth = 1000 # to get the effect of having just the states without a map &quot;background&quot; # turn off the background patch and axes frame ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal(), frameon=False) ax.patch.set_visible(False) ax.set_extent([-125, -66.5, 20, 50], ccrs.Geodetic()) ax.set_title(&#39;US States sales in $ n (red/orange/yellow : less than $1K/2K/3K)&#39;) # load US states boundaries shapename = &#39;admin_1_states_provinces_lakes&#39; states_shp = shpreader.natural_earth(resolution=&#39;110m&#39;, category=&#39;cultural&#39;, name=shapename) # colormap to get colors based on a value (from 0 to max) cmap = mpl.cm.Blues(np.linspace(0, 1, int(df_2.max())+1)) print(cmap) # for all states in the shapefile for state in shpreader.Reader(states_shp).records(): state_name = state.attributes[&#39;name&#39;].rstrip(&#39; x00&#39;) try: value = int(df_2[state_name]) except KeyError: value = 0 #print(state_name, value, cmap[value]) if value &lt; min_worth: color = &#39;red&#39; elif value &lt; 2*min_worth: color = &#39;darkorange&#39; elif value &lt; 3*min_worth: color = &#39;yellow&#39; else: color = cmap[value] # add a colored state ax.add_geometries( [state.geometry], ccrs.PlateCarree(), facecolor=color, edgecolor=&#39;black&#39;, #styler=colorize_state #func ) ax2 = fig.add_axes([0.95,0.10,0.05,0.85]) norm = mpl.colors.Normalize(vmin=0,vmax=df_2.max()+1) cb1 = mpl.colorbar.ColorbarBase(ax2,cmap=mpl.cm.Blues,norm=norm,orientation=&#39;vertical&#39;) plt.show() . [[0.96862745 0.98431373 1. 1. ] [0.96862745 0.98431373 1. 1. ] [0.96862745 0.98431373 1. 1. ] ... [0.03137255 0.18823529 0.41960784 1. ] [0.03137255 0.18823529 0.41960784 1. ] [0.03137255 0.18823529 0.41960784 1. ]] . import matplotlib.pyplot as plt #print(df.columns) # Index([&#39;Row ID&#39;, &#39;Order ID&#39;, &#39;Order Date&#39;, Ship Date&#39;, &#39;Ship Mode&#39;, # &#39;Customer ID&#39;, &#39;Customer Name&#39;, &#39;Segment&#39;, &#39;Country&#39;, &#39;City&#39;, # &#39;State&#39;, &#39;Postal Code&#39;, &#39;Region&#39;, &#39;Product ID&#39;, &#39;Category&#39;, # &#39;Sub-Category&#39;, &#39;Product Name&#39;, &#39;Sales&#39;], dtype=&#39;object&#39;) # Convert to panda date df[&#39;Order Date 2&#39;] = pd.to_datetime(df[&#39;Order Date&#39;], format=&#39;%d/%m/%Y&#39;) #print(df[&#39;Order Date 2&#39;]) df.set_index([&#39;Order Date 2&#39;], inplace=True) # reset_index : to keep columns (names) ordered_sales = df.groupby([&#39;Order Date 2&#39;])[&#39;Sales&#39;].sum().reset_index() #print(ordered_sales.columns) # Index([&#39;Sales&#39;], dtype=&#39;object&#39;) print(ordered_sales) # 1230 lines (days on 4 years) start_date = ordered_sales[&#39;Order Date 2&#39;].min() end_date = ordered_sales[&#39;Order Date 2&#39;].max() #print(start_date, end_date) # 2015-01-03 00:00:00 2018-12-30 00:00:00 #idx = pd.date_range(start=start_date, end=end_date, freq=&#39;D&#39;) # 1458 days : DatetimeIndex([&#39;2015-01-03&#39;, ..., &#39;2018-12-30&#39;]) #ordered_sales[&#39;Order Date&#39;].index = pd.DatetimeIndex(pd.to_datetime(ordered_sales[&#39;Order Date&#39;], format=&#39;%d/%m/%Y&#39;).index) #ordered_sales[&#39;Sales&#39;] = ordered_sales[&#39;Sales&#39;].reindex(idx, fill_value=0) #print(ordered_sales.set_index(&#39;Order Date&#39;)) #plt.figure(figsize=(20,5)) fig, ax = plt.subplots(figsize=(20,5)) ax.plot(ordered_sales[&#39;Order Date 2&#39;], ordered_sales[&#39;Sales&#39;]) ax.set_title(&#39;Sales in $ per day&#39;) ax.set_xlabel(&#39;Date&#39;) ax.set_ylabel(&#39;Dollar ($)&#39;) ax.set_xlim(pd.Timestamp(&#39;2015-01-01&#39;), pd.Timestamp(&#39;2018-12-31&#39;)) plt.show() . Order Date 2 Sales 0 2015-01-03 16.4480 1 2015-01-04 288.0600 2 2015-01-05 19.5360 3 2015-01-06 4407.1000 4 2015-01-07 87.1580 ... ... ... 1225 2018-12-26 814.5940 1226 2018-12-27 177.6360 1227 2018-12-28 1657.3508 1228 2018-12-29 2915.5340 1229 2018-12-30 713.7900 [1230 rows x 2 columns] . import seaborn as sns sns.set_theme(style=&quot;whitegrid&quot;) cmap = sns.cubehelix_palette(rot=-.2, as_cmap=True) df[&quot;Duration&quot;] = (pd.to_datetime(df[&quot;Ship Date&quot;], format=&#39;%d/%m/%Y&#39;) - pd.to_datetime(df[&quot;Order Date&quot;], format=&#39;%d/%m/%Y&#39;)).astype(&#39;timedelta64[h]&#39;).astype(np.int32) / 24 g = sns.relplot( data=df[[&#39;Sales&#39;, &#39;Duration&#39;]], x=&quot;Sales&quot;, y=&quot;Duration&quot;, #hue=&quot;year&quot;, size=&quot;mass&quot;, palette=cmap, sizes=(10, 200), ) g.set(xscale=&quot;log&quot;) g.ax.xaxis.grid(True, &quot;minor&quot;, linewidth=.25) g.ax.yaxis.grid(True, &quot;minor&quot;, linewidth=.25) g.despine(left=True, bottom=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f0fabb22550&gt; . test = df.loc[:, [&#39;Category&#39;, &#39;Sub-Category&#39;]]==[&#39;Furniture&#39;, &#39;Bookcases&#39;] print(test.head()) print(&quot;-&quot;*30) print(test.value_counts()) print(&quot;-&quot;*30) print(test.nunique()) . Category Sub-Category Order Date 2 2017-11-08 True True 2017-11-08 True False 2017-06-12 False False 2016-10-11 True False 2016-10-11 False False Category Sub-Category False False 7722 True False 1852 True 226 dtype: int64 Category 2 Sub-Category 2 dtype: int64 . bookcases = df.query(&quot;Category == &#39;Furniture&#39; &amp; `Sub-Category` == &#39;Bookcases&#39;&quot;) # filter on 2 columns (Logical AND) print(&quot;Filtered dataset&#39;s size :&quot;, bookcases.shape) # (226 rows, 18 columns) print(&quot;-&quot;*10+&quot; counts of distinct values &quot;+&quot;-&quot;*10) print(bookcases[&#39;Ship Mode&#39;].value_counts()) print(&quot;-&quot;*10+&quot;&quot;+&quot;-&quot;*10) print(&quot;Number of distinct values :&quot;, bookcases[&#39;Ship Mode&#39;].nunique()) . Filtered dataset&#39;s size : (226, 21) - counts of distinct values - Standard Class 123 Second Class 48 First Class 48 Same Day 7 Name: Ship Mode, dtype: int64 -- Number of distinct values : 4 . test = bookcases.loc[:, [&#39;Ship Mode&#39;, &#39;State&#39;]]==[&#39;Standard Class&#39;, &#39;California&#39;] #print(test) print(test[[&#39;Ship Mode&#39;, &#39;State&#39;]].value_counts()) . Ship Mode State True False 96 False False 79 True True 27 False True 24 dtype: int64 . print(&quot;-&quot;*30) print(bookcases[[&#39;Ship Mode&#39;, &#39;State&#39;]].value_counts()) print(&quot;-&quot;*30) print(bookcases.nunique()) . Ship Mode State Standard Class California 27 New York 18 Texas 16 First Class California 11 Second Class California 10 .. Missouri 1 Same Day Connecticut 1 Second Class Virginia 1 Utah 1 First Class South Dakota 1 Length: 67, dtype: int64 Row ID 226 Order ID 222 Order Date 199 Ship Date 209 Ship Mode 4 Customer ID 194 Customer Name 194 Segment 3 Country 1 City 108 State 33 Postal Code 136 Region 4 Product ID 49 Category 1 Sub-Category 1 Product Name 50 Sales 196 month 12 year 4 Duration 8 dtype: int64 . print(df.query(&quot;State == &#39;California&#39; &amp; Segment == &#39;Corporate&#39;&quot;).shape) # (601 rows, 18 feature columns) . (601, 21) . CORRELATIONs . df[&quot;Duration&quot;] = (pd.to_datetime(df[&quot;Ship Date&quot;], format=&#39;%d/%m/%Y&#39;) - pd.to_datetime(df[&quot;Order Date&quot;], format=&#39;%d/%m/%Y&#39;)).astype(&#39;timedelta64[h]&#39;).astype(np.int32) / 24 print(df[[&#39;Sales&#39;, &#39;Duration&#39;]].corr()) # method=&#39;pearson&#39; (by default) # =&gt; 0.005712 print(df[[&#39;Sales&#39;, &#39;Duration&#39;]].corr(method=&#39;spearman&#39;)) # for non-linear correlation... # =&gt; 0.014283 . Sales Duration Sales 1.000000 -0.005712 Duration -0.005712 1.000000 Sales Duration Sales 1.000000 -0.014283 Duration -0.014283 1.000000 . Plot univariate (or bivariate distributions) using kernel density estimation https://seaborn.pydata.org/generated/seaborn.kdeplot.html . print(df.columns) df.reset_index(inplace=True) sns.kdeplot(data=df, x=&#39;Sales&#39;) . Index([&#39;Order Date 2&#39;, &#39;Row ID&#39;, &#39;Order ID&#39;, &#39;Order Date&#39;, &#39;Ship Date&#39;, &#39;Ship Mode&#39;, &#39;Customer ID&#39;, &#39;Customer Name&#39;, &#39;Segment&#39;, &#39;Country&#39;, &#39;City&#39;, &#39;State&#39;, &#39;Postal Code&#39;, &#39;Region&#39;, &#39;Product ID&#39;, &#39;Category&#39;, &#39;Sub-Category&#39;, &#39;Product Name&#39;, &#39;Sales&#39;, &#39;month&#39;, &#39;year&#39;, &#39;Duration&#39;], dtype=&#39;object&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0f9d9f7090&gt; . sns.kdeplot(df[&#39;Duration&#39;], cumulative=True) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0fa605ff90&gt; . sns.displot(df[&#39;Sales&#39;], color=&quot;g&quot;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f0fa6151350&gt; . sns.pairplot(df[[&#39;Sales&#39;, &#39;Duration&#39;]]) . &lt;seaborn.axisgrid.PairGrid at 0x7f0fa525b250&gt; . sns.histplot(data=df, x=&#39;Sales&#39;, y=&#39;Duration&#39;, hue=&#39;Ship Mode&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0fa4070d10&gt; . sns.histplot(df[[&#39;Duration&#39;]], kde=True) # divided in 100 parts (=bins) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0fa41b9c10&gt; . plt.figure(figsize=(25,5)) sns.histplot(df[[&#39;Sales&#39;]], bins=100) # divided in 100 parts (=bins) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0f9daf86d0&gt; . c1 = df[&#39;State&#39;].where((df[&#39;State&#39;] == &#39;California&#39;) | (df[&#39;State&#39;] == &#39;New York&#39;)) c2 = df.Duration.isin([0, 1, 2]) # Fast ? # Summary table : sns.heatmap(pd.crosstab( c1, c2, #normalize=True, # rows sum to 1 margins=True, margins_name=&#39;Total&#39; ), cmap=&quot;YlGnBu&quot;, annot=True, fmt=&quot;d&quot;, cbar=False) df_test = pd.concat([c1, c2], axis=1, keys=[&#39;State&#39;, &#39;isFast&#39;]) # same results / other method df_test.groupby([&#39;State&#39;, &#39;isFast&#39;])[&#39;State&#39;].count().unstack().fillna(0) . isFast False True . State . California 1464 | 482 | . New York 869 | 228 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df[[&#39;Sales&#39;, &#39;Duration&#39;]].cov() . Sales Duration . Sales 332395.829672 | -24.923792 | . Duration -24.923792 | 3.165217 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; ts = pd.Series(np.random.randn(1000), index=pd.date_range(&quot;1/1/2000&quot;, periods=1000)) ts = ts.cumsum() ts.plot(); df_four = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(&quot;ABCD&quot;)) df_four = df_four.cumsum() plt.figure() df.plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f0f9d766a10&gt; . Error in callback &lt;function install_repl_displayhook.&lt;locals&gt;.post_execute at 0x7f0fc939e050&gt; (for post_execute): . ValueError Traceback (most recent call last) /usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py in post_execute() 107 def post_execute(): 108 if matplotlib.is_interactive(): --&gt; 109 draw_all() 110 111 # IPython &gt;= 2 /usr/local/lib/python3.7/dist-packages/matplotlib/_pylab_helpers.py in draw_all(cls, force) 125 for f_mgr in cls.get_all_fig_managers(): 126 if force or f_mgr.canvas.figure.stale: --&gt; 127 f_mgr.canvas.draw_idle() 128 129 atexit.register(Gcf.destroy_all) /usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py in draw_idle(self, *args, **kwargs) 1945 if not self._is_idle_drawing: 1946 with self._idle_draw_cntx(): -&gt; 1947 self.draw(*args, **kwargs) 1948 1949 @cbook.deprecated(&#34;3.2&#34;) /usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py in draw(self) 391 (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar 392 else nullcontext()): --&gt; 393 self.figure.draw(self.renderer) 394 # A GUI class may be need to update a window using this draw, so 395 # don&#39;t forget to call the superclass. /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/figure.py in draw(self, renderer) 1734 self.patch.draw(renderer) 1735 mimage._draw_list_compositing_images( -&gt; 1736 renderer, self, artists, self.suppressComposite) 1737 1738 renderer.close_group(&#39;figure&#39;) /usr/local/lib/python3.7/dist-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite) 135 if not_composite or not has_images: 136 for a in artists: --&gt; 137 a.draw(renderer) 138 else: 139 # Composite any adjacent images together /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py in draw(self, renderer, inframe) 2628 renderer.stop_rasterizing() 2629 -&gt; 2630 mimage._draw_list_compositing_images(renderer, self, artists) 2631 2632 renderer.close_group(&#39;axes&#39;) /usr/local/lib/python3.7/dist-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite) 135 if not_composite or not has_images: 136 for a in artists: --&gt; 137 a.draw(renderer) 138 else: 139 # Composite any adjacent images together /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in draw(self, renderer, *args, **kwargs) 1225 renderer.open_group(__name__, gid=self.get_gid()) 1226 -&gt; 1227 ticks_to_draw = self._update_ticks() 1228 ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw, 1229 renderer) /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in _update_ticks(self) 1101 the axes. Return the list of ticks that will be drawn. 1102 &#34;&#34;&#34; -&gt; 1103 major_locs = self.get_majorticklocs() 1104 major_labels = self.major.formatter.format_ticks(major_locs) 1105 major_ticks = self.get_major_ticks(len(major_locs)) /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in get_majorticklocs(self) 1346 def get_majorticklocs(self): 1347 &#34;&#34;&#34;Get the array of major tick locations in data coordinates.&#34;&#34;&#34; -&gt; 1348 return self.major.locator() 1349 1350 def get_minorticklocs(self): /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in __call__(self) 1336 def __call__(self): 1337 &#39;Return the locations of the ticks&#39; -&gt; 1338 self.refresh() 1339 return self._locator() 1340 /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in refresh(self) 1362 def refresh(self): 1363 # docstring inherited -&gt; 1364 dmin, dmax = self.viewlim_to_dt() 1365 self._locator = self.get_locator(dmin, dmax) 1366 /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in viewlim_to_dt(self) 1096 &#39;often happens if you pass a non-datetime &#39; 1097 &#39;value to an axis that has datetime units&#39; -&gt; 1098 .format(vmin)) 1099 return num2date(vmin, self.tz), num2date(vmax, self.tz) 1100 ValueError: view limit minimum -36852.9 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units . &lt;Figure size 432x288 with 0 Axes&gt; . ValueError Traceback (most recent call last) /usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py in __call__(self, obj) 332 pass 333 else: --&gt; 334 return printer(obj) 335 # Finally look for special method names 336 method = get_real_method(obj, self.print_method) /usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py in &lt;lambda&gt;(fig) 239 240 if &#39;png&#39; in formats: --&gt; 241 png_formatter.for_type(Figure, lambda fig: print_figure(fig, &#39;png&#39;, **kwargs)) 242 if &#39;retina&#39; in formats or &#39;png2x&#39; in formats: 243 png_formatter.for_type(Figure, lambda fig: retina_figure(fig, **kwargs)) /usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py in print_figure(fig, fmt, bbox_inches, **kwargs) 123 124 bytes_io = BytesIO() --&gt; 125 fig.canvas.print_figure(bytes_io, **kw) 126 data = bytes_io.getvalue() 127 if fmt == &#39;svg&#39;: /usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs) 2098 else suppress()) 2099 with ctx: -&gt; 2100 self.figure.draw(renderer) 2101 bbox_artists = kwargs.pop(&#34;bbox_extra_artists&#34;, None) 2102 bbox_inches = self.figure.get_tightbbox(renderer, /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/figure.py in draw(self, renderer) 1734 self.patch.draw(renderer) 1735 mimage._draw_list_compositing_images( -&gt; 1736 renderer, self, artists, self.suppressComposite) 1737 1738 renderer.close_group(&#39;figure&#39;) /usr/local/lib/python3.7/dist-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite) 135 if not_composite or not has_images: 136 for a in artists: --&gt; 137 a.draw(renderer) 138 else: 139 # Composite any adjacent images together /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py in draw(self, renderer, inframe) 2628 renderer.stop_rasterizing() 2629 -&gt; 2630 mimage._draw_list_compositing_images(renderer, self, artists) 2631 2632 renderer.close_group(&#39;axes&#39;) /usr/local/lib/python3.7/dist-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite) 135 if not_composite or not has_images: 136 for a in artists: --&gt; 137 a.draw(renderer) 138 else: 139 # Composite any adjacent images together /usr/local/lib/python3.7/dist-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs) 36 renderer.start_filter() 37 &gt; 38 return draw(artist, renderer, *args, **kwargs) 39 finally: 40 if artist.get_agg_filter() is not None: /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in draw(self, renderer, *args, **kwargs) 1225 renderer.open_group(__name__, gid=self.get_gid()) 1226 -&gt; 1227 ticks_to_draw = self._update_ticks() 1228 ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw, 1229 renderer) /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in _update_ticks(self) 1101 the axes. Return the list of ticks that will be drawn. 1102 &#34;&#34;&#34; -&gt; 1103 major_locs = self.get_majorticklocs() 1104 major_labels = self.major.formatter.format_ticks(major_locs) 1105 major_ticks = self.get_major_ticks(len(major_locs)) /usr/local/lib/python3.7/dist-packages/matplotlib/axis.py in get_majorticklocs(self) 1346 def get_majorticklocs(self): 1347 &#34;&#34;&#34;Get the array of major tick locations in data coordinates.&#34;&#34;&#34; -&gt; 1348 return self.major.locator() 1349 1350 def get_minorticklocs(self): /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in __call__(self) 1336 def __call__(self): 1337 &#39;Return the locations of the ticks&#39; -&gt; 1338 self.refresh() 1339 return self._locator() 1340 /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in refresh(self) 1362 def refresh(self): 1363 # docstring inherited -&gt; 1364 dmin, dmax = self.viewlim_to_dt() 1365 self._locator = self.get_locator(dmin, dmax) 1366 /usr/local/lib/python3.7/dist-packages/matplotlib/dates.py in viewlim_to_dt(self) 1096 &#39;often happens if you pass a non-datetime &#39; 1097 &#39;value to an axis that has datetime units&#39; -&gt; 1098 .format(vmin)) 1099 return num2date(vmin, self.tz), num2date(vmax, self.tz) 1100 ValueError: view limit minimum -36852.9 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units . &lt;Figure size 432x288 with 1 Axes&gt; .",
            "url": "https://yannick42.github.io/notebooks/fastpages/jupyter/eda/2022/04/22/Superstore_Sales_Dataset_(EDA).html",
            "relUrl": "/fastpages/jupyter/eda/2022/04/22/Superstore_Sales_Dataset_(EDA).html",
            "date": " • Apr 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://yannick42.github.io/notebooks/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://yannick42.github.io/notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://yannick42.github.io/notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}